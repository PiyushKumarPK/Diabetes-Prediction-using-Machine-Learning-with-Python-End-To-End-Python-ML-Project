# -*- coding: utf-8 -*-
"""Diabetes Prediction using Machine Learning with Python.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17OKhkbl8LEtx_zAs-fpaSGGB3quYShw3

**Importing the Dependencies**
"""

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn import svm
from sklearn.metrics import accuracy_score

""" **Data collection and Analysis,
PIMA Diabetes dataset**
"""

#loading a diabetes dataset to a pandas dataframe
diabetes_dataset = pd.read_csv('/content/diabetes.csv')

#printing the first 5 dataset
diabetes_dataset.head()

# number of rows and coloumns in this dataset
diabetes_dataset.shape

#getting the statistical measures of the data
diabetes_dataset.describe()

#diabetics and non-diabetics example
diabetes_dataset['Outcome'].value_counts()

"""0 ---> Non-Diabetic ,
1 ---> Diabetic
"""

#Try to get mean of all those value for this label zero and one
diabetes_dataset.groupby('Outcome').mean()

#Separating the data and labels  [Labels means separate outcome columns]
X = diabetes_dataset.drop(columns = 'Outcome', axis = 1)
Y = diabetes_dataset['Outcome']

print(X)
# All the data except the outcome

print(Y)
#Outcome Column

"""**Data Standardization -**  In machine learning (ML), standardized data is data that has been converted into a consistent format so that it can be processed and analyzed"""

from sklearn.preprocessing import StandardScaler

#Here scaler is variable
scaler = StandardScaler()

scaler.fit(X)

standarized_data  = scaler.transform(X)

print(standarized_data)

# Above all the values in between 0 and 1

# so we are taking all this standarized data and feedind it to variable X and Outcome label Y
X = standarized_data
Y = diabetes_dataset['Outcome']
# we will use this X and Y for training  our Machinr lerning model so basically X represents the data Y represents model

print(X)
print(Y)

"""**Train test split**

we need to split our data into training data and test data
"""

from sklearn.model_selection import train_test_split

# so we need to mention four varibles here (X_train, X_test, Y_train, Y_test) so we can use the function (train_test_split)
X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.2, stratify=Y, random_state=2)

print(X.shape, X_train.shape, X_test.shape)
#There are totally 768 examples in our original dataset out of those 614 are going to be used for training data and 154 will be our test data

"""**Training the Model**"""

from sklearn import svm

#we are going to training the model
# Here classifier is variable
classifier = svm.SVC(kernel='linear')

#Training the support vector machine classifier
classifier.fit(X_train, Y_train)
#So this has trained our ML model

"""**Model Evaluation**"""

#Now we can evalute our model
#So basically evaluation is to check how many times our model is predicting correctly

"""**Accuracy Score**"""

from sklearn.metrics import accuracy_score

#So first lets try to find the accuracy score on the training data so we will try to predict all these training data
#So we will not give the machine learning model Y_train labels so we will try to predict the label for all these training data(X_train) and we will compare the prediction of our model to the original labels which is Y labels and predict the accuracy score

# Here(X_train_prediction and training_data_accuracy is variable
#we are using trained ML model  (classifier fit) this trained model is stored in to variable now we are comparing the prediction of our model which is stored in to variable (X_train_prediction) with the original labels that is Y_train
X_train_prediction = classifier.predict(X_train)
training_data_accuracy = accuracy_score(X_train_prediction,Y_train)

print('Accuracy score of the training data : ', training_data_accuracy)

"""**Accuracy score on the testing data**"""

X_test_prediction = classifier.predict(X_test)
test_data_accuracy = accuracy_score(X_test_prediction,Y_test)

print('Accuracy score of the training data : ', test_data_accuracy)

#Now we need to make a predictive system that can predict whether a person has diabetes or not
# All these data so we have 	(Pregnancies	Glucose	BloodPressure	SkinThickness	Insulin	BMI	DiabetesPedigreeFunction	Age)
#Once we give all these data our machine learning model has to predict whether that person has diabetes or not
#Now we are going to bulid that system

"""**Making a Predictive System**"""

#input data so in this array called as input data we need to give all those medical information that is the (Pregnancies	Glucose	BloodPressure	SkinThickness	Insulin	BMI	DiabetesPedigreeFunction	Age)
#So this will be input data
#So we need to give these medical informations and the model has to predict whether the label is zero or one
#So one reprsents diabetic patients and zero represents non-diabetic patients
#So lets just select a random example so i will just select any row from dataset [5,116,74,0,0,25.6,0.201,30,0] last values represent outcome which is  0 which represent the person is [Non-diabetics]
#So we are taking all data except outcome
#we will feed this data to our machine model and it should predict the outcome will be zero which represents the patient is non-diabetic

input_data = (5,116,74,0,0,25.6,0.201,30)

#Now we have to change this input data to numpy array
#So this basically is a list data type and we are going to change to a numpy array because the processing and numpy array is more easy and efficient so we are going to change the input data to numpy array
#So we already import numpy as np
#So we can follow this same procedure for different projects where we want to make a predictive system so this is just like a blueprint
#So this will remains almost the same for different predictive system

input_data_as_numpy_array = np.asarray(input_data)

#Now we need reshape this data
#reshape the array as we are predicting for one instance
#So our model is trained on 768 examples and there are totally eight columns in our model training
#But in this case we are just using one data point
#If we do not reshape the array what the model expects is it expects 768 values but we just giving one So this we will make a confusion to the model and hence we need to reshape the array and this reshape will tell the model that we are just going to need the prediction for only one data points
#So that is the reason for this
#so we create numpy array as input_data_reshaped = input_data_as_numpy_array.reshape
#reshape is the function we are going to use for this reshape belongs to the library numpy so reshape (1,-1) so this is the parameter for the reshaping
#So this will tell the model that we are not giving 768 examples we are just trying to predict the label for only one instance so this will reshape

input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)

#STANDARDIZE THE INPUT DATA
#There is one more important thing we cannot give this values as such because while training our model we have standarized the data
#So we have not used the raw data as such now what we have to do is we have to do same procedure here because if we give this data such as our model cannot make prediction correctly
#So we need to standarize the data in the same manner as we standardize our training data
#So we have already fitted to X in scaler.fit(X) which is training data and we need to use the same function scalar here so we do not have fit it again we just need to transform it based on scalar

std_data = scaler.transform(input_data_reshaped)
print(std_data)

#Now lets make the prediction so we have made ML model so we have trained the model and we have stored it in the variable called classifier
#This classifier has the trained the support vector machine model so we need to use that variable classifier and we need to use the function predict
#So we are standardizing the data and we are feeding the standarized data to our machine learning model
#So we can note here that we have not included the label here so the model has to predict the label correctly


#Now the model has to predict that the person is non-diabetic because we have taken the example for a non-diabetic case so we can see the label in dataset is 0 So i have to call the values here
#Now the model has to give the label as 0
#So lets try to print this prediction so i am creating the prediction here

prediction = classifier.predict(std_data)
print(prediction)

if (prediction[0] == 0):
  print('The person is non-diabetic')
else:
  print('The person is diabetic')

#So above two line represents our standarized data so this (5,116,74,0,0,25.6,0.201,30) is data we are giving and this data is standardized based on our standard scalar function
#[[ 0.3429808  -0.15318486  0.25303625 -1.28821221 -0.69289057 -0.81134119  -0.81807858 -0.27575966]] this is the standard value so we can see here it is almost in the same range and this value is fed to our trained machine learning model which is stored in to variable called as classififer and we are predicting the label for this std_data and we got the prediction from the model as zero
#our model has predicted correctly the label for this data

"""**Now try for diabetic case**"""

#[0,137,40,35,168,43.1,2.288,33,1] here last digit is one so it is diabetic

input_data = (0,137,40,35,168,43.1,2.288,33)


input_data_as_numpy_array = np.asarray(input_data)


input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)


std_data = scaler.transform(input_data_reshaped)
print(std_data)


prediction = classifier.predict(std_data)
print(prediction)

if (prediction[0] == 0):
  print('The person is non-diabetic')
else:
  print('The person is diabetic')